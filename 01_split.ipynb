{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # default_exp fileManagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide \n",
    "# %load_ext autoreload \n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Coding/ModelAssistedLabel\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%cd \"/content/drive/MyDrive/Coding/ModelAssistedLabel\"\n",
    "# %run \"./00_ultralytics.ipynb\"\n",
    "# \n",
    "from ModelAssistedLabel.core import Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstracting File Management\n",
    "\n",
    "Each file has its own assumptions about file structure. I use these classes to organize images and labels into the appropriate location at the appropriate time.\n",
    "\n",
    "```\n",
    "- OTHER_DIR_WITH_CUSTOM_DATA\n",
    "  - bag-of-images-and-labels\n",
    "\n",
    "- ROOT DIRECTORY\n",
    "  - test/\n",
    "  - valid/\n",
    "  - train/\n",
    "  - data.yaml\n",
    "  - yolov5/\n",
    "      - train.py\n",
    "      - detect.py\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import glob\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "class FileUtilities:\n",
    "  \"\"\"\n",
    "  Set of utility functions for managing the requirements of the Ultralytics repo\n",
    "  \"\"\"\n",
    "\n",
    "  def resource_map():\n",
    "    \"\"\"\n",
    "    Explicity define the extensions for images and labels. Check the `Default` class's\n",
    "    `resource_map` values\n",
    "    \"\"\"\n",
    "    return Defaults().resource_map\n",
    "\n",
    "  def collect_files(walk_dir, recursive):\n",
    "    \"\"\"\n",
    "    By default, returns all the \".jpg\" and \".txt\" files in a directory. The filetypes\n",
    "    are specified by the :resource_map:.\n",
    "\n",
    "    Args:\n",
    "      walk_dir: directory from which to pull resources\n",
    "      recursive: if `True`, resursively searches the folder for the desired resource.\n",
    "    \n",
    "    Returns:\n",
    "      A dictionary keyed to the :resource_map: with each value being an array of \n",
    "      the keyed type.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, extension in FileUtilities.resource_map().items():\n",
    "      resource_generator = glob.iglob(walk_dir + '/**/*' + extension, recursive=recursive)\n",
    "      res[key] = [{\"pair_id\": os.path.basename(x)[:-1*len(extension)], \"path\": x, \"basename\":os.path.basename(x)} for x in resource_generator]\n",
    "    return res\n",
    "\n",
    "  def matched(file_collection):\n",
    "    \"\"\"\n",
    "    Pairs up an image and label based on a shared resource name.\n",
    "\n",
    "    Arges:\n",
    "      res: the result of a \n",
    "    \"\"\"\n",
    "    bn = lambda x: set([z[\"pair_id\"] for z in x])\n",
    "    matched = (bn(file_collection[\"labels\"]).intersection(bn(file_collection[\"images\"])))\n",
    "    pairs = []\n",
    "    for resource in matched:\n",
    "      tmp = {}\n",
    "      for k in FileUtilities.resource_map():\n",
    "        tmp[k] = [x for x in file_collection[k] if x[\"pair_id\"] == resource][0]\n",
    "      pairs.append(tmp)\n",
    "      \n",
    "    return pairs\n",
    "\n",
    "  def match_files(walk_dir, recursive=True):\n",
    "    \"\"\"\n",
    "    From a bag of resources, find the paired images and labels.\n",
    "\n",
    "    Args:\n",
    "      walk_dir: recursively search for images/labels within this folder\n",
    "\n",
    "    Returns:\n",
    "      matched pairs of images and text within the `walk_dir`\n",
    "    \"\"\"\n",
    "    return FileUtilities.matched(FileUtilities.collect_files(walk_dir, recursive=recursive))\n",
    "\n",
    "  def mkdir(dir):\n",
    "    \"\"\"\n",
    "    Don't overwrite an existing file when calling mkdir.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if not os.path.exists(dir):\n",
    "      os.mkdir(f\"{dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from ModelAssistedLabel.core import Defaults\n",
    "from datetime import datetime\n",
    "import math, random\n",
    "\n",
    "class Generation:\n",
    "  \"\"\"\n",
    "    Container and organizer of photos for a given repository. This class \"softly\"\n",
    "    organizes the files upon the setting of the `split` attribute via `set_split`.\n",
    "\n",
    "    The split can then be written to disk by calling `write_split_to_disk`. The\n",
    "    relevant data will be zipped in `out_dir`\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, repo, out_dir, data_yaml):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        repo: <string> path to the parent directory of the repository.\n",
    "    \"\"\"\n",
    "    self.repo = repo\n",
    "    self.split = None\n",
    "    self.data_yaml = data_yaml\n",
    "    self.out_dir = out_dir\n",
    "\n",
    "  def set_split(self, split_ratio = None, MAX_SIZE=None):\n",
    "    \"\"\"\n",
    "    Sets the value of `self.split` \n",
    "\n",
    "    Args:\n",
    "      split_ratio: relative fractions of split between test train and validation\n",
    "      sets.\n",
    "      MAX_SIZE: The total number of images to be used in the image set \n",
    "    \"\"\"\n",
    "    if split_ratio is None:\n",
    "      split_ratio = Defaults().split_ratio\n",
    "\n",
    "    files = FileUtilities.match_files(self.repo)\n",
    "    random.shuffle(files)\n",
    "    if MAX_SIZE:\n",
    "      files = files[:MAX_SIZE]\n",
    "\n",
    "    train = math.ceil(len(files) * split_ratio[\"train\"])\n",
    "    valid = train + math.ceil(len(files) * split_ratio[\"valid\"])\n",
    "\n",
    "    split =  {\"train\": files[:train],\n",
    "    \"valid\": files[train: valid],\n",
    "    \"test\": files[valid:]}\n",
    "\n",
    "    assert sum([len(split[x]) for x in split]) == len(files)\n",
    "    self.split = split\n",
    "  \n",
    "\n",
    "  def write_split_to_disk(self, descriptor = \"\", autoname_output=True):\n",
    "    \"\"\"\n",
    "    Takes the given `self.split` and writes the split of the data to disk. Also\n",
    "    writes a data.yaml file to retain class label information.\n",
    "\n",
    "    Args:\n",
    "      descriptor: <str> a unique identifier for the output's filename\n",
    "      autoname_output: <bool> if True, `descriptor` field is a component of the\n",
    "      output's filename. Otherwise, it is the entire name.\n",
    "\n",
    "    Returns:\n",
    "      A path to the zipped information.\n",
    "    \"\"\"\n",
    "    assert self.split is not None\n",
    "\n",
    "    if autoname_output:\n",
    "      out_folder = self.__default_filename__(descriptor)\n",
    "    else:\n",
    "      assert len(descriptor) > 0, \"need to provide a filename with `descriptor` argument\"\n",
    "      out_folder = descriptor\n",
    "      \n",
    "    dirs = self.__write_images__() #write images\n",
    "    zipped = self.__zip_dirs__(out_folder, dirs) #zip folders\n",
    "    os.system(f\"mv '{zipped}' '{self.out_dir}'\") #move the output\n",
    "    return f\"{self.out_dir}/{zipped}\"\n",
    "\n",
    "\n",
    "  def __zip_dirs__(self, folder, dirs):\n",
    "    \"\"\"\n",
    "    Takes an array of resources and places them all as the children in a specified\n",
    "    `folder`.\n",
    "\n",
    "    Args:\n",
    "      folder: Ultimately will be transformed into `folder.zip`\n",
    "      dirs: resources to become zipped\n",
    "\n",
    "    Returns:\n",
    "      the name of the zip file uniting the resources in `dirs`\n",
    "    \"\"\"\n",
    "    FileUtilities.mkdir(folder)\n",
    "    self.__write_data_yaml__(folder)\n",
    "    for subdir in self.split:\n",
    "      os.system(f\"mv './{subdir}' '{folder}/'\")\n",
    "\n",
    "    os.system(f'zip -r \"{folder}.zip\" \"{folder}\"')\n",
    "    os.system(f'rm -f -r \"{folder}\"')\n",
    "    return f\"{folder}.zip\"\n",
    "\n",
    "  \n",
    "  def __write_images__(self):\n",
    "    \"\"\"\n",
    "    If the dataset has already been split, then write the files to disk accordingly.\n",
    "    All resources are present two levels deep. The top folders are named according\n",
    "    to \"test\"/\"train\"/\"valid\". The mid-level folders are named \"images\" or \"labels\".\n",
    "    Resources can be found in the corresponding folder.\n",
    "\n",
    "    Returns:\n",
    "      A list of directories to the test/train/valid split\n",
    "    \"\"\"\n",
    "    assert self.split is not None\n",
    "    directories = []\n",
    "    for dirname, pairs in self.split.items(): \n",
    "      dir = join(\"./\", dirname) #test/valid/train\n",
    "      FileUtilities.mkdir(dir)\n",
    "      directories.append(dir)\n",
    "      for pair in pairs:\n",
    "        for resource, data in pair.items():\n",
    "          subdir = join(dir, resource)\n",
    "          FileUtilities.mkdir(subdir)\n",
    "\n",
    "          target = data[\"path\"]\n",
    "          destination = join(subdir, data[\"basename\"])\n",
    "          print(\"target/dest\", target, \"|\", destination)\n",
    "          if not os.path.exists(destination): \n",
    "            os.system(f\"cp '{target}' '{destination}'\")\n",
    "    return directories\n",
    "    \n",
    "  def __default_filename__(self, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Helper to ease the burden of continually generating unique names or accidentally\n",
    "    overwriting important data.\n",
    "\n",
    "    Args:\n",
    "      prefix: zipfile identifier\n",
    "    \"\"\"\n",
    "    now = datetime.now() # current date and time\n",
    "    timestamp = now.strftime(\" %y-%m-%d %H-%M-%S\")\n",
    "    zipname = self.repo.split(\"/\")[-1] + prefix + timestamp\n",
    "    return zipname\n",
    "\n",
    "  def __write_data_yaml__(self, folder, filename=\"data.yaml\"):\n",
    "    \"\"\"\n",
    "    Write `self.data_yaml` to disk.\n",
    "\n",
    "    Args:\n",
    "      folder: directory in which to write the data\n",
    "      filename: optionally rename the yaml data's file\n",
    "    \"\"\"\n",
    "    f = open(os.path.join(folder, filename),\"w+\")\n",
    "    f.writelines(self.data_yaml)\n",
    "    f.close()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
