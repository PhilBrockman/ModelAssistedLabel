{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%%capture\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide \n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Coding/ModelAssistedLabel\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "%cd \"/content/drive/MyDrive/Coding/ModelAssistedLabel\"\n",
    "# %run \"./00_ultralytics.ipynb\"\n",
    "# \n",
    "from ModelAssistedLabel.core import Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanup zip files\n",
      "Converted 00_ultralytics.ipynb.\n",
      "Converted 01_split.ipynb.\n",
      "Converted 02_augment.ipynb.\n",
      "Converted index.ipynb.\n",
      "converting: /content/drive/My Drive/Coding/ModelAssistedLabel/01_split.ipynb\n",
      "converting: /content/drive/My Drive/Coding/ModelAssistedLabel/index.ipynb\n",
      "converting: /content/drive/My Drive/Coding/ModelAssistedLabel/00_ultralytics.ipynb\n",
      "converting: /content/drive/My Drive/Coding/ModelAssistedLabel/02_augment.ipynb\n",
      "converting /content/drive/My Drive/Coding/ModelAssistedLabel/index.ipynb to README.md\n",
      "Executing: git config --local include.path ../.gitconfig\n",
      "Success: hooks are installed and repo's .gitconfig is now trusted\n",
      "[master e3c553b] cleanup zip files\n",
      " 12 files changed, 220 insertions(+), 486 deletions(-)\n",
      "Counting objects: 18, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (17/17), done.\n",
      "Writing objects: 100% (18/18), 4.57 KiB | 360.00 KiB/s, done.\n",
      "Total 18 (delta 11), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (11/11), completed with 11 local objects.\u001b[K\n",
      "To https://github.com/PhilBrockman/ModelAssistedLabel.git\n",
      "   9865394..e3c553b  master -> master\n"
     ]
    }
   ],
   "source": [
    "%run \"_Synch.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ##Case-sensitive file extensions.\n",
    "\n",
    "#@markdown Defaults filetypes are based on the pattern in Roboflow's export.\n",
    "images = \".jpg\" #@param {type:\"string\"}\n",
    "labels = \".txt\" #@param {type:\"string\"}\n",
    "\n",
    "resource_map = {\"images\": images, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import glob\n",
    "from os.path import join\n",
    "\n",
    "class FileUtilities:\n",
    "  def collect_files(walk_dir, recursive):\n",
    "    \"\"\"\n",
    "    By default, returns all the \".jpg\" and \".txt\" files in a directory. The filetypes\n",
    "    are specified by the :resource_map:.\n",
    "\n",
    "    Args:\n",
    "      walk_dir: directory from which to pull resources\n",
    "      recursive: if `True`, resursively searches the folder for the desired resource.\n",
    "    \n",
    "    Returns:\n",
    "      A dictionary keyed to the :resource_map: with each value being an array of \n",
    "      the keyed type.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key, extension in resource_map.items():\n",
    "      resource_generator = glob.iglob(walk_dir + '/**/*' + extension, recursive=recursive)\n",
    "      res[key] = [{\"pair_id\": os.path.basename(x)[:-1*len(extension)], \"path\": x, \"basename\":os.path.basename(x)} for x in resource_generator]\n",
    "    return res\n",
    "\n",
    "  def matched(file_collection):\n",
    "    \"\"\"\n",
    "    Pairs up an image and label based on a shared resource name.\n",
    "\n",
    "    Arges:\n",
    "      res: the result of a \n",
    "    \"\"\"\n",
    "    bn = lambda x: set([z[\"pair_id\"] for z in x])\n",
    "    matched = (bn(file_collection[\"labels\"]).intersection(bn(file_collection[\"images\"])))\n",
    "    pairs = []\n",
    "    for resource in matched:\n",
    "      tmp = {}\n",
    "      for k in resource_map:\n",
    "        tmp[k] = [x for x in file_collection[k] if x[\"pair_id\"] == resource][0]\n",
    "      pairs.append(tmp)\n",
    "      \n",
    "    return pairs\n",
    "\n",
    "  def match_files(walk_dir, recursive=True):\n",
    "    return FileUtilities.matched(FileUtilities.collect_files(walk_dir, recursive=recursive))\n",
    "\n",
    "  def mkdir(dir):\n",
    "\n",
    "    import os\n",
    "    if not os.path.exists(dir):\n",
    "      os.mkdir(f\"{dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from ModelAssistedLabel.core import Defaults\n",
    "from datetime import datetime\n",
    "import math, random\n",
    "\n",
    "class Generation:\n",
    "  \"\"\"\n",
    "    Container and organizer of photos for a given repository.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, repo, out_dir, data_yaml):\n",
    "    \"\"\"\n",
    "      Args:\n",
    "        repo: <string> path to the parent directory of the repository.\n",
    "    \"\"\"\n",
    "    self.repo = repo\n",
    "    self.split = None\n",
    "    self.data_yaml = data_yaml\n",
    "    self.out_dir = out_dir\n",
    "\n",
    "  def set_split(self, split_ratio = None, MAX_SIZE=None):\n",
    "    \"\"\"\n",
    "    Sets the value of `self.split` \n",
    "\n",
    "    Args:\n",
    "      split_ratio: relative fractions of split between test train and validation\n",
    "      sets.\n",
    "      MAX_SIZE: The total number of images to be used in the image set \n",
    "    \"\"\"\n",
    "    if split_ratio is None:\n",
    "      split_ratio = Defaults().split_ratio\n",
    "\n",
    "    files = FileUtilities.match_files(self.repo)\n",
    "    random.shuffle(files)\n",
    "    if MAX_SIZE:\n",
    "      files = files[:MAX_SIZE]\n",
    "\n",
    "    train = math.ceil(len(files) * split_ratio[\"train\"])\n",
    "    valid = train + math.ceil(len(files) * split_ratio[\"valid\"])\n",
    "\n",
    "    split =  {\"train\": files[:train],\n",
    "    \"valid\": files[train: valid],\n",
    "    \"test\": files[valid:]}\n",
    "\n",
    "    assert sum([len(split[x]) for x in split]) == len(files)\n",
    "    self.split = split\n",
    "  \n",
    "\n",
    "  def process_split(self, descriptor = \"\", autoname_output=True):\n",
    "    \"\"\"\n",
    "    Takes the given `self.split` and writes the split of the data to disk. Also\n",
    "    writes a data.yaml file to retain class label information.\n",
    "\n",
    "    Args:\n",
    "      descriptor: <str> a unique identifier for the output's filename\n",
    "      autoname_output: <bool> if True, `descriptor` field is a component of the\n",
    "      output's filename. Otherwise, it is the entire name.\n",
    "\n",
    "    Returns:\n",
    "      A path to the zipped information.\n",
    "    \"\"\"\n",
    "    assert self.split is not None\n",
    "\n",
    "    if autoname_output:\n",
    "      out_folder = self.default_filename(descriptor)\n",
    "    else:\n",
    "      assert len(descriptor) > 0, \"need to provide a filename with `descriptor` argument\"\n",
    "      out_folder = descriptor\n",
    "      \n",
    "    dirs = self.write_images() #write images\n",
    "    zipped = self.zip_dirs(out_folder, dirs) #zip folders\n",
    "    os.system(f\"mv '{zipped}' '{self.out_dir}'\") #move the output\n",
    "    return f\"{self.out_dir}/{zipped}\"\n",
    "\n",
    "\n",
    "  def zip_dirs(self, folder, dirs):\n",
    "    \"\"\"\n",
    "    Takes an array of resources and places them all as the children in a specified\n",
    "    `folder`.\n",
    "\n",
    "    Args:\n",
    "      folder: Ultimately will be transformed into `folder.zip`\n",
    "      dirs: resources to become zipped\n",
    "\n",
    "    Returns:\n",
    "      the name of the zip file uniting the resources in `dirs`\n",
    "    \"\"\"\n",
    "    FileUtilities.mkdir(folder)\n",
    "    self.write_data_yaml(folder)\n",
    "    for subdir in self.split:\n",
    "      os.system(f\"mv './{subdir}' '{folder}/'\")\n",
    "\n",
    "    os.system(f'zip -r \"{folder}.zip\" \"{folder}\"')\n",
    "    os.system(f'rm -f -r \"{folder}\"')\n",
    "    return f\"{folder}.zip\"\n",
    "\n",
    "  \n",
    "  def write_images(self):\n",
    "    \"\"\"\n",
    "    If the dataset has already been split, then write the files to disk accordingly.\n",
    "    All resources are present two levels deep. The top folders are named according\n",
    "    to \"test\"/\"train\"/\"valid\". The mid-level folders are named \"images\" or \"labels\".\n",
    "    Resources can be found in the corresponding folder.\n",
    "\n",
    "    Returns:\n",
    "      A list of directories to the test/train/valid split\n",
    "    \"\"\"\n",
    "    assert self.split is not None\n",
    "    directories = []\n",
    "    for dirname, pairs in self.split.items(): \n",
    "      dir = join(\"./\", dirname) #test/valid/train\n",
    "      FileUtilities.mkdir(dir)\n",
    "      directories.append(dir)\n",
    "      for pair in pairs:\n",
    "        for resource, data in pair.items():\n",
    "          subdir = join(dir, resource)\n",
    "          FileUtilities.mkdir(subdir)\n",
    "\n",
    "          target = data[\"path\"]\n",
    "          destination = join(subdir, data[\"basename\"])\n",
    "          print(\"target/dest\", target, \"|\", destination)\n",
    "          if not os.path.exists(destination): \n",
    "            os.system(f\"cp '{target}' '{destination}'\")\n",
    "    return directories\n",
    "    \n",
    "  def default_filename(self, prefix=\"\"):\n",
    "    \"\"\"\n",
    "    Helper to ease the burden of continually generating unique names or accidentally\n",
    "    overwriting important data.\n",
    "\n",
    "    Args:\n",
    "      prefix: \n",
    "    \"\"\"\n",
    "    now = datetime.now() # current date and time\n",
    "    timestamp = now.strftime(\" %y-%m-%d %H-%M-%S\")\n",
    "    zipname = self.repo.split(\"/\")[-1] + prefix + timestamp\n",
    "    return zipname\n",
    "\n",
    "  def write_data_yaml(self, folder=\"./\"):\n",
    "    f = open(join(folder, \"data.yaml\"),\"w+\")\n",
    "    f.writelines(self.data_yaml)\n",
    "    f.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test a use case. Define the `repo` or the location of the images and their associated labels. `out_dir` is where the zipped and organized information is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/screenytake-89-jpg-cropped-jpg_jpg.rf.fddb40a647c590aeb2c2e68408ade165.jpg | ./train/images/screenytake-89-jpg-cropped-jpg_jpg.rf.fddb40a647c590aeb2c2e68408ade165.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/screenytake-89-jpg-cropped-jpg_jpg.rf.fddb40a647c590aeb2c2e68408ade165.txt | ./train/labels/screenytake-89-jpg-cropped-jpg_jpg.rf.fddb40a647c590aeb2c2e68408ade165.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/save_dirrdigittake-81-jpg-cropped-jpg-jpg_jpg.rf.cf8ab96262f1fd76f49b4ecef63d28b9.jpg | ./train/images/save_dirrdigittake-81-jpg-cropped-jpg-jpg_jpg.rf.cf8ab96262f1fd76f49b4ecef63d28b9.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/save_dirrdigittake-81-jpg-cropped-jpg-jpg_jpg.rf.cf8ab96262f1fd76f49b4ecef63d28b9.txt | ./train/labels/save_dirrdigittake-81-jpg-cropped-jpg-jpg_jpg.rf.cf8ab96262f1fd76f49b4ecef63d28b9.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/digittake-327-jpg_jpg.rf.51a6a64a1c8528eab30e68ab241cbab0.jpg | ./train/images/digittake-327-jpg_jpg.rf.51a6a64a1c8528eab30e68ab241cbab0.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/digittake-327-jpg_jpg.rf.51a6a64a1c8528eab30e68ab241cbab0.txt | ./train/labels/digittake-327-jpg_jpg.rf.51a6a64a1c8528eab30e68ab241cbab0.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/save_dirrtake-144-jpg-cropped-jpg-jpg_jpg.rf.fd13cc583c84b0af10c32d02450b5d53.jpg | ./valid/images/save_dirrtake-144-jpg-cropped-jpg-jpg_jpg.rf.fd13cc583c84b0af10c32d02450b5d53.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/save_dirrtake-144-jpg-cropped-jpg-jpg_jpg.rf.fd13cc583c84b0af10c32d02450b5d53.txt | ./valid/labels/save_dirrtake-144-jpg-cropped-jpg-jpg_jpg.rf.fd13cc583c84b0af10c32d02450b5d53.txt\n"
     ]
    }
   ],
   "source": [
    "g = Generation(repo = \"/content/drive/MyDrive/Coding/Roboflow Export (841)\", \n",
    "               out_dir = \"/content/drive/MyDrive/Coding/01_train\",\n",
    "               data_yaml=Defaults().data_yaml)\n",
    "\n",
    "g.set_split(MAX_SIZE=4)\n",
    "out_dir = g.process_split(\" processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that no files will be overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(os.path.exists(os.path.basename(out_dir)), False)\n",
    "z = os.path.basename(out_dir)\n",
    "!mv \"{out_dir}\" . #help clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unzip and check if the number of files is as expected according to `g.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./Roboflow Export (841) processor 21-03-15 19-13-22.zip\n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/\n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/train/\n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/train/images/\n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/train/images/screenytake-89-jpg-cropped-jpg_jpg.rf.fddb40a647c590aeb2c2e68408ade165.jpg  \n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/train/images/save_dirrdigittake-81-jpg-cropped-jpg-jpg_jpg.rf.cf8ab96262f1fd76f49b4ecef63d28b9.jpg  \n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/train/images/digittake-327-jpg_jpg.rf.51a6a64a1c8528eab30e68ab241cbab0.jpg  \n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/train/labels/\n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/train/labels/screenytake-89-jpg-cropped-jpg_jpg.rf.fddb40a647c590aeb2c2e68408ade165.txt  \n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/train/labels/save_dirrdigittake-81-jpg-cropped-jpg-jpg_jpg.rf.cf8ab96262f1fd76f49b4ecef63d28b9.txt  \n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/train/labels/digittake-327-jpg_jpg.rf.51a6a64a1c8528eab30e68ab241cbab0.txt  \n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/valid/\n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/valid/images/\n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/valid/images/save_dirrtake-144-jpg-cropped-jpg-jpg_jpg.rf.fd13cc583c84b0af10c32d02450b5d53.jpg  \n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/valid/labels/\n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/valid/labels/save_dirrtake-144-jpg-cropped-jpg-jpg_jpg.rf.fd13cc583c84b0af10c32d02450b5d53.txt  \n",
      "   creating: Roboflow Export (841) processor 21-03-15 19-13-22/test/\n",
      "  inflating: Roboflow Export (841) processor 21-03-15 19-13-22/data.yaml  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"./{z}\"\n",
    "ls = !ls \"{z[:-4]}/train/labels\"\n",
    "test_eq(len(ls), 3)\n",
    "ls = !ls \"{z[:-4]}/valid/labels\"\n",
    "test_eq(len(ls), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the test zip file and zipped file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def clean_zip(zip):\n",
    "  os.system(f'rm -f -r \"{zip[:-4]}\"')\n",
    "  os.system(f'rm \"{zip}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_zip(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(os.path.exists(os.path.basename(out_dir)), False)\n",
    "test_eq_type(os.path.exists(out_dir), False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
