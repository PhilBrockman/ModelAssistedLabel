# AUTOGENERATED! DO NOT EDIT! File to edit: 01_split.ipynb (unless otherwise specified).

__all__ = ['FileUtilities', 'Generation']

# Cell

import glob
from os.path import join
import os

class FileUtilities:
  """
  Set of utility functions for managing the requirements of the Ultralytics repo
  """

  def resource_map():
    """
    Explicity define the extensions for images and labels. Check the `Default` class's
    `resource_map` values
    """
    return Defaults().resource_map

  def collect_files(walk_dir, recursive):
    """
    By default, returns all the ".jpg" and ".txt" files in a directory. The filetypes
    are specified by the :resource_map:.

    Args:
      walk_dir: directory from which to pull resources
      recursive: if `True`, resursively searches the folder for the desired resource.

    Returns:
      A dictionary keyed to the :resource_map: with each value being an array of
      the keyed type.
    """
    res = {}
    for key, extension in FileUtilities.resource_map().items():
      resource_generator = glob.iglob(walk_dir + '/**/*' + extension, recursive=recursive)
      res[key] = [{"pair_id": os.path.basename(x)[:-1*len(extension)], "path": x, "basename":os.path.basename(x)} for x in resource_generator]
    return res

  def matched(file_collection):
    """
    Pairs up an image and label based on a shared resource name.

    Arges:
      res: the result of a
    """
    bn = lambda x: set([z["pair_id"] for z in x])
    matched = (bn(file_collection["labels"]).intersection(bn(file_collection["images"])))
    pairs = []
    for resource in matched:
      tmp = {}
      for k in FileUtilities.resource_map():
        tmp[k] = [x for x in file_collection[k] if x["pair_id"] == resource][0]
      pairs.append(tmp)

    return pairs

  def match_files(walk_dir, recursive=True):
    """
    From a bag of resources, find the paired images and labels.

    Args:
      walk_dir: recursively search for images/labels within this folder

    Returns:
      matched pairs of images and text within the `walk_dir`
    """
    return FileUtilities.matched(FileUtilities.collect_files(walk_dir, recursive=recursive))


# Cell
from .core import Defaults
from datetime import datetime
import math, random, shutil
import progressbar

class Generation:
  """
    Container and organizer of photos for a given repository. This class "softly"
    organizes the files upon the setting of the `split` attribute via `set_split`.

    The split can then be written to disk by calling `write_split_to_disk`. The
    relevant data will be zipped in `out_dir`
  """

  def __init__(self, repo, out_dir, data_yaml=None, verbose=True, resource_dirs = ["train", "valid", "test"]):
    """
      Args:
        repo: <string> path to the parent directory of the repository.
        out_dir: directory in which the zip file will be written
        data_yaml: bridge between the "class indices" and "class labels"
        verbose: spam `standard out` with info about files
        resource_dirs: Ultralytics default names
    """
    self.repo = repo
    self.split = None
    self.data_yaml = data_yaml
    self.out_dir = out_dir
    self.verbose = verbose
    self.resource_dirs = resource_dirs

  def set_split_from_disk(self):
    "sets the value of `self.split` to images present in train/valid/test folders on disk."
    self.split = [{x: os.listdir(x)} for x in self.resource_dirs]

  def set_split(self, split_ratio = None, MAX_SIZE=None):
    """
    Sets the value of `self.split`

    Args:
      split_ratio: relative fractions of split between test train and validation
      sets.
      MAX_SIZE: The total number of images to be used in the image set. By default
      includes all available images
    """
    if split_ratio is None:
      split_ratio = Defaults().split_ratio

    files = FileUtilities.match_files(self.repo)
    random.shuffle(files)
    if MAX_SIZE is not None:
      files = files[:MAX_SIZE]

    train = math.ceil(len(files) * split_ratio["train"])
    valid = train + math.ceil(len(files) * split_ratio["valid"])

    split =  {"train": files[:train],
    "valid": files[train: valid],
    "test": files[valid:]}

    assert sum([len(split[x]) for x in split]) == len(files)
    self.split = split

  def get_split(self):
    return [{x: len(self.split[x])} for x in self.split]

  def write_split_to_disk(self, descriptor = "", autoname_output=True):
    """
    Takes the given `self.split` and writes the split of the data to disk. Also
    writes a data.yaml file to retain class label information.

    Args:
      descriptor: <str> a unique identifier for the output's filename
      autoname_output: <bool> if True, `descriptor` field is a component of the
      output's filename. Otherwise, sets the output filename to `{descriptor}.zip`

    Returns:
      A path to the zipped information.
    """
    assert self.split is not None

    if autoname_output:
      out_folder = self.__default_filename__(descriptor)
    else:
      assert len(descriptor) > 0, "need to provide a filename with `descriptor` argument"
      out_folder = descriptor

    dirs = self.__write_images__() #write images
    print('dirs', dirs)
    zipped = self.__zip_dirs__(out_folder, dirs) #zip folders
    return zipped


  def __zip_dirs__(self, zip_name, dirs):
    """
    Takes an array of resources and places them all as the children in a specified
    `zip_name`.

    Args:
      zip_name: Ultimately will be transformed into `{zip_name}.zip`
      dirs: resources to become zipped

    Returns:
      the name of the zip file uniting the resources in `dirs`
    """
    outpath = os.path.join(self.out_dir, zip_name)
    assert not os.path.exists(outpath)
    os.makedirs(outpath, exist_ok=True)
    yaml_file = self.__write_data_yaml__(folder=outpath)
    print("yaml", yaml_file)
    for subdir in self.split:
      if self.verbose:
        print("subdir", subdir)
        print("\toutdir", outpath)
      shutil.move(subdir, outpath)

    print("os.listdir", os.listdir(outpath))

    os.system(f'zip -r "{outpath}.zip" "{outpath}"')
    os.system(f'rm -f -r "{outpath}"')
    return f"{outpath}.zip"


  def __write_images__(self):
    """
    If the dataset has already been split, then write the files to disk accordingly.
    All resources are present two levels deep. The top folders are named according
    to "test"/"train"/"valid". The mid-level folders are named "images" or "labels".
    Resources can be found in the corresponding folder.

    Returns:
      A list of directories to the test/train/valid split
    """
    assert self.split is not None
    directories = []
    counter = 0
    print()
    for dirname, pairs in self.split.items():
      dir = join("./", dirname) #test/valid/train
      directories.append(dir)
      for pair in pairs:
        counter += 1
        for resource, data in pair.items():
          subdir = join(dir, resource)
          os.makedirs(subdir, exist_ok=True)

          target = data["path"]
          full_out = os.path.join(subdir, data["basename"])

          if not os.path.exists(full_out):
            shutil.copyfile(target, full_out)
            if self.verbose:
              print(f"({counter}) copying:", target, end='\r')
    return directories

  def __default_filename__(self, prefix=""):
    """
    Helper to ease the burden of continually generating unique names or accidentally
    overwriting important data.

    Args:
      prefix: zipfile identifier
    """
    now = datetime.now() # current date and time
    timestamp = now.strftime(" %y-%m-%d %H-%M-%S")
    zipname = self.repo.split("/")[-1] + prefix + timestamp
    return zipname

  def __write_data_yaml__(self, folder, filename="data.yaml"):
    """
    Write `self.data_yaml` to disk.

    Args:
      folder: directory in which to write the data
      filename: optionally rename the yaml data's file
    """
    outfile = os.path.join(folder, filename)

    if os.path.exists(outfile):
      os.remove(outfile)

    f = open(outfile,"w")
    if self.data_yaml is None:
      f.writelines(Defaults().data_yaml)
    else:
      f.writelines(self.data_yaml)
    f.close()
    assert os.path.exists(outfile)
    return outfile
