{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"01_train.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"09QJSLNJeeK4"},"source":["# default_exp core"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNApuO8teqsF","executionInfo":{"status":"ok","timestamp":1615765561878,"user_tz":240,"elapsed":21506,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}},"outputId":"6f1ca8f3-71af-4754-dd59-300a000a8404"},"source":["#hide\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FFyKHtKsfFhV","executionInfo":{"status":"ok","timestamp":1615765044286,"user_tz":240,"elapsed":5148,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}}},"source":["#hide\n","import os\n","# define pathway to the weights\n","weight_filenames = {\n","    \"lcd\": \"21-2-20-94-universal-lcd.pt\",\n","    \"digits\":'21-2-25 1k-digits YOLOv5-weights.pt'\n","    }\n","\n","resource_folder = \"/content/drive/MyDrive/Coding/Roboflow/try it out\"\n","\n","# detectors = []\n","# for filename in weight_filenames:\n","# weights_path = os.path.join(resource_folder, weights_filename)\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xR-SBpXexXko","executionInfo":{"status":"ok","timestamp":1615765051064,"user_tz":240,"elapsed":11920,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}},"outputId":"05bd4350-de7d-4e91-ae1a-97c91a9e0d2a"},"source":["import os\n","\n","# safety for re-executions\n","if not os.path.exists(\"yolov5\"):\n","  # clone YOLOv5 and reset to a specific git checkpoint that has been verified working\n","  !git clone https://github.com/ultralytics/yolov5  # clone repo\n","  !git reset --hard 68211f72c99915a15855f7b99bf5d93f5631330f\n","\n","# enter the yolov5 directory\n","%cd yolov5\n","\n","# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","# from utils.google_utils import gdrive_download  # to download models/datasets\n","\n","clear_output()\n","\n","if torch.cuda.is_available():\n","  print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0)))\n","else:\n","  raise Exception(\"You need to enable GPU in this runtime environment\")\n","\n","# return to parent directory\n","%cd .."],"execution_count":4,"outputs":[{"output_type":"stream","text":["Setup complete. Using torch 1.8.0+cu101 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n","/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O9eNwYdgeeK-"},"source":["# module name here\n","\n","> API details."]},{"cell_type":"code","metadata":{"id":"UoTOzx-jgzM-","executionInfo":{"status":"ok","timestamp":1615765051064,"user_tz":240,"elapsed":4981,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}}},"source":["images = \".jpg\"\n","labels = \".txt\"\n","\n","resource_map = {\"images\": images, \"labels\": labels}"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBkuFWc2QQAz","executionInfo":{"status":"ok","timestamp":1615765137413,"user_tz":240,"elapsed":427,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}}},"source":["# export\n","\n","import glob\n","from os.path import join\n","\n","class FileUtilities:\n","  def collect_files(walk_dir, recursive):\n","    \"\"\"\n","    By default, returns all the \".jpg\" and \".txt\" files in a directory. The filetypes\n","    are specified by the :resource_map:.\n","\n","    Args:\n","      walk_dir: directory from which to pull resources\n","      recursive: if `True`, resursively searches the folder for the desired resource.\n","    \n","    Returns:\n","      A dictionary keyed to the :resource_map: with each value being an array of \n","      the keyed type.\n","    \"\"\"\n","    res = {}\n","    for key, extension in resource_map.items():\n","      resource_generator = glob.iglob(walk_dir + '/**/*' + extension, recursive=recursive)\n","      res[key] = [{\"pair_id\": os.path.basename(x)[:-1*len(extension)], \"path\": x, \"basename\":os.path.basename(x)} for x in resource_generator]\n","    return res\n","\n","  def matched(file_collection):\n","    \"\"\"\n","    Pairs up an image and label based on a shared resource name.\n","\n","    Arges:\n","      res: the result of a \n","    \"\"\"\n","    bn = lambda x: set([z[\"pair_id\"] for z in x])\n","    matched = (bn(file_collection[\"labels\"]).intersection(bn(file_collection[\"images\"])))\n","    pairs = []\n","    for resource in matched:\n","      tmp = {}\n","      for k in resource_map:\n","        tmp[k] = [x for x in file_collection[k] if x[\"pair_id\"] == resource][0]\n","      pairs.append(tmp)\n","      \n","    return pairs\n","\n","  def match_files(walk_dir, recursive=True):\n","    return FileUtilities.matched(FileUtilities.collect_files(walk_dir, recursive=recursive))\n","\n","  def mkdir(dir):\n","    import os\n","    if not os.path.exists(dir):\n","      os.mkdir(f\"{dir}\")\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLjF5QE9pPHO","executionInfo":{"status":"ok","timestamp":1615765327244,"user_tz":240,"elapsed":476,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}}},"source":["# export\n","\n","\n","from datetime import datetime\n","import math, random\n","\n","class Generation:\n","  \"\"\"\n","    Container and organizer of photos for a given repository.\n","  \"\"\"\n","\n","  def default_split_ratio(self):\n","    return {\n","              \"train\": .7,\n","              \"valid\": .2,\n","              \"test\": .1 \n","            }\n","\n","  def __init__(self, repo):\n","    \"\"\"\n","      Args:\n","        repo: <string> path to the parent directory of the repository.\n","    \"\"\"\n","    self.repo = repo\n","    self.split = None\n","    self.data_yaml = data_yaml\n","    self.out_dir = out_dir\n","\n","  def split_repo(self, split_ratio = None, MAX_SIZE=None):\n","    \"\"\"\n","    Sets the value of `self.split` \n","\n","    Args:\n","      split_ratio: relative fractions of split between test train and validation\n","      sets.\n","      MAX_SIZE: The total number of images to be used in the image set \n","    \"\"\"\n","    if split_ratio is None:\n","      split_ratio = self.default_split_ratio()\n","\n","    files = FileUtilities.match_files(repo)\n","    random.shuffle(files)\n","    if MAX_SIZE:\n","      files = files[:MAX_SIZE]\n","\n","    train = math.ceil(len(files) * split_ratio[\"train\"])\n","    valid = train + math.ceil(len(files) * split_ratio[\"valid\"])\n","\n","    split =  {\"train\": files[:train],\n","    \"valid\": files[train: valid],\n","    \"test\": files[valid:]}\n","\n","    assert sum([len(split[x]) for x in split]) == len(files)\n","    self.split = split\n","  \n","  def write_images(self):\n","    \"\"\"\n","    If the dataset has already been split, then write the files to disk accordingly.\n","    All resources are present two levels deep. The top folders are named according\n","    to \"test\"/\"train\"/\"valid\". The mid-level folders are named \"images\" or \"labels\".\n","    Resources can be found in the corresponding folder.\n","\n","    Returns:\n","      A list of directories to the test/train/valid split\n","    \"\"\"\n","    assert self.split is not None\n","    directories = []\n","    for dirname, pairs in self.split.items(): \n","      dir = join(\"./\", dirname) #test/valid/train\n","      FileUtilities.mkdir(dir)\n","      directories.append(dir)\n","      for pair in pairs:\n","        for resource, data in pair.items():\n","          subdir = join(dir, resource)\n","          FileUtilities.mkdir(subdir)\n","\n","          target = data[\"path\"]\n","          destination = join(subdir, data[\"basename\"])\n","          if not os.path.exists(destination): \n","            os.system(f\"cp {target} {destination}\")\n","    return directories\n","\n","  def zip_splits_to_destination(self, folder=None):\n","    assert self.split is not None\n","    if folder is None:\n","      folder = self.unified_dirname()\n","    dirs = self.write_images()\n","    zipped = self.unify_dirs(folder, dirs)\n","    os.system(f\"mv '{folder}.zip' '{self.out_dir}'\")\n","    return f\"{self.out_dir}/{folder}.zip\"\n","\n","  def unify_dirs(self, folder, dirs):\n","    FileUtilities.mkdir(folder)\n","    self.write_data_yaml(folder)\n","    for subdir in self.split:\n","      os.system(f\"mv './{subdir}' '{folder}/'\")\n","\n","    os.system(f'zip -r \"{folder}.zip\" \"{folder}\"')\n","    os.system(f'rm -f -r \"{folder}\"')\n","    return f\"{folder}.zip\"\n","    \n","  def unified_dirname(self, prefix=\"\"):\n","    now = datetime.now() # current date and time\n","    timestamp = now.strftime(\" %y-%m-%d %H-%M-%S\")\n","    zipname = self.repo.split(\"/\")[-1] + prefix + timestamp\n","    return zipname\n","\n","  def write_data_yaml(self, folder=\"./\"):\n","    f = open(join(folder, \"data.yaml\"),\"w+\")\n","    f.writelines(self.data_yaml)\n","    f.close()\n","  "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BfV7X6qgpI1b","executionInfo":{"status":"ok","timestamp":1615765393603,"user_tz":240,"elapsed":975,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}},"outputId":"f29b3d21-9c16-4606-bbec-5f3ef01aeae9"},"source":["\n","data_yaml = \"\"\"train: ../train/images\n","  val: ../valid/images\n","\n","  nc: 10\n","  names: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\"\"\"\n","\n","out_dir = \"/content/drive/MyDrive/Coding/01_train\"\n","repo = \"/content/drive/MyDrive/Coding/Roboflow Export (841)\"\n","\n","g = Generation(repo)\n","g.split_repo(MAX_SIZE=3)\n","print([{x: len(g.split[x])} for x in g.split])\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["[{'train': 0}, {'valid': 0}, {'test': 0}]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caH23gscICRc","executionInfo":{"status":"ok","timestamp":1615765459820,"user_tz":240,"elapsed":538,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}},"outputId":"e5f51fab-0e0f-4732-8a0d-296b08894576"},"source":["!ls \"{g.repo}\""],"execution_count":16,"outputs":[{"output_type":"stream","text":["ls: cannot access '/content/drive/MyDrive/Coding/Roboflow Export (841)': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BTXF1BKzIPaA","executionInfo":{"status":"ok","timestamp":1615765508179,"user_tz":240,"elapsed":415,"user":{"displayName":"Phil Brockman","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhRQ6c2Urd5EK4o6JVa0PviRJ-05jgpKhdJT6ytFA=s64","userId":"14019256435810739333"}},"outputId":"6f820b5d-94cf-49bc-f678-6ca1d729e34c"},"source":["ls /content/drive/MyDrive/Coding"],"execution_count":19,"outputs":[{"output_type":"stream","text":["'1st Period Resources.gsite'\n","'2.1.3 agenda - Pie chart 1.gsheet'\n","'2:30pm, 12 3 20.gdoc'\n"," 23_1.m4v\n","'3.1.3 shared workspace template.gslides'\n"," 4.1.1.gslides\n","'4.1.2 Resource Page.gdoc'\n","'4-1 Template.gdoc'\n","'6th (mgg-kydu-mwg - Oct 23, 2020).gjam'\n","'Answer Key: 1-3 through 1-7 - Column chart 1.gsheet'\n"," Attendance.gsheet\n","'Attendance & Participation.gsheet'\n","'Blakeney Parent Emails.gsheet'\n","'Brockman Parents 12 9.gsheet'\n","\u001b[0m\u001b[01;34m\"Brockman's LIVE file uploader\"\u001b[0m/\n","\u001b[01;34m'calling parents'\u001b[0m/\n"," \u001b[01;34mClassroom\u001b[0m/\n","'Copy of 2:30pm, 12 3 20.gdoc'\n","'Copy of Callahan EquatIO Mathspace Links - Texthelp Public Information (1).gdoc'\n","'Copy of Callahan EquatIO Mathspace Links - Texthelp Public Information.gdoc'\n","'Copy of Copy of Guide (DRAFT) for Teaching CPM’s PC3, Calculus, Statistics Remotely (1).gsheet'\n","'Copy of Copy of Guide (DRAFT) for Teaching CPM’s PC3, Calculus, Statistics Remotely.gsheet'\n","'Copy of Observation Conference-Brockman.gdoc'\n","'Copy of Return Rosters.xlsx'\n","'Copy of Test Corrections.gslides'\n","'cyq-kvuk-dnv - Mar 8, 2021 (1).gjam'\n","'cyq-kvuk-dnv - Mar 8, 2021.gjam'\n","\u001b[01;34m'Department PD'\u001b[0m/\n","'eb7uimtpx2 (osz-zwqz-yut - Dec 8, 2020).gjam'\n","'FCHS Student Mental Wellness Training.webm'\n","'Geometry (Brockman) (Aidan Powell) (eed-kdeb-cye - Oct 29, 2020).gjam'\n","'Geometry (Brockman) (Isaiah Jones) (und-xiuf-orr - Nov 11, 2020).gjam'\n","'Geometry (Brockman) (Jala Cothran) (ypz-qsyv-nmz - Oct 23, 2020).gjam'\n","'Geometry (Brockman) (Kaseady Daugherty) (fmk-yacb-sjc - Oct 27, 2020).gjam'\n","'Geometry (Brockman) (Matthew Mcdaniel) (few-yuza-qhd - Oct 7, 2020).gjam'\n","'Geometry (Brockman) (melisa) (npu-wsee-upw - Oct 28, 2020).gjam'\n","'Geometry (Brockman) (Phil Brockman) (wib-ekeu-gcp - Dec 16, 2020).gjam'\n","'Geometry (Brockman) (Reyna Aguilera) (jsa-vwqc-jtg - Oct 23, 2020).gjam'\n","'Goal: Graduation.gdoc'\n"," IMG_1689.JPG\n"," IMG_1690.JPG\n","\u001b[01;34m'Meeting Reports'\u001b[0m/\n","\u001b[01;34m'Meet Recordings'\u001b[0m/\n","'mgg-kydu-mwg - Nov 13, 2020.gjam'\n","\u001b[01;34m'NTI Newsletter'\u001b[0m/\n","\u001b[01;34m'nti stats'\u001b[0m/\n","\u001b[01;34m'overages 2020-21'\u001b[0m/\n","'Participation Challenge.jpg'\n","\u001b[01;34m'Pear Deck'\u001b[0m/\n","'Race Times.gdraw'\n"," \u001b[01;34mScreencastify\u001b[0m/\n","'Screen Shot 2020-09-01 at 8.59.47 PM.png'\n","'Screen Shot 2020-09-10 at 9.53.39 AM.png'\n","'Screen Shot 2020-09-11 at 3.01.43 PM.png'\n","'Screen Shot 2020-09-11 at 3.02.47 PM.png'\n","'Screen Shot 2020-09-11 at 3.03.37 PM.png'\n","'Screen Shot 2020-11-19 at 4.54.44 PM.png'\n","'Sept 2 update.gdoc'\n","'Team 1: 4-37.gdoc'\n","'Team 2: 4-37.gdoc'\n","'Team 4 - 3.2.3 Simulations of Probability.gjam'\n","'Team 5 - 3.2.3 Simulations of Probability.gjam'\n","\u001b[01;34m'Tech Projects'\u001b[0m/\n","'title (1).gslides'\n"," title.gslides\n","'Unit 4: Quiz #1  modified.gsheet'\n","\u001b[01;34m'unorganized mess'\u001b[0m/\n","'Untitled document (1).gdoc'\n","'Untitled document (2).gdoc'\n","'Untitled document (3).gdoc'\n","'Untitled document (4).gdoc'\n","'Untitled document.gdoc'\n","'Untitled drawing (1).gdraw'\n","'Untitled drawing (2).gdraw'\n","'Untitled drawing.gdraw'\n","'Untitled form.gform'\n","'Untitled Jam (1).gjam'\n","'Untitled Jam (2).gjam'\n","'Untitled Jam (3).gjam'\n","'Untitled Jam (4).gjam'\n","'Untitled Jam (5).gjam'\n","'Untitled Jam (6).gjam'\n","'Untitled Jam (7).gjam'\n","'Untitled Jam.gjam'\n","'Untitled presentation (1).gslides'\n","'Untitled presentation.gslides'\n","'Untitled spreadsheet (1).gsheet'\n","'Untitled spreadsheet (2).gsheet'\n","'Untitled spreadsheet.gsheet'\n","'urg-htiq-vtv - Nov 9, 2020.gjam'\n","'Vaccine Form filled out.pdf'\n"," Visors.gdraw\n","'vzc-qevf-khs - Dec 17, 2020.gjam'\n","'vzc-qevf-khs - Oct 22, 2020.gjam'\n","'vzc-qevf-khs - Oct 26, 2020.gjam'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f2Mq8PLvH0Xx"},"source":["folder_name = g.unified_dirname(prefix=\" no augments\")\n","d = g.zip_splits_to_destination(folder_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OFXvsHf4c5V"},"source":["!cp \"{d}\" \"./{folder_name}.zip\"\n","!rm -f \"{d}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmO1mE4-yPSm","outputId":"fd60570b-2f4f-4f77-e6a8-930f6b6691a7"},"source":["!unzip \"{folder_name}.zip\" -d \"{folder_name}\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  Roboflow Export (841) no augments 21-03-14 18-19-19.zip\n","   creating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/\n","   creating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/\n","   creating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/labels/\n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/labels/digittake-23-jpg_jpg.rf.00548b600c00b9a0159307cccf3347f1.txt  \n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/labels/save_dirrsave_dirr36a73c74ef0b76639e12488651f587fb06a9baab-jpg-jpg_jpg.rf.cd4c51c05581425f5ff10b194f12f1e0.txt  \n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/labels/save_dirrtake-12_jpg_cropped-jpg_jpg.rf.52431525a8df960d1e777c49ac53bd81.txt  \n","   creating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/images/\n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/images/save_dirrsave_dirr36a73c74ef0b76639e12488651f587fb06a9baab-jpg-jpg_jpg.rf.cd4c51c05581425f5ff10b194f12f1e0.jpg  \n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/images/digittake-23-jpg_jpg.rf.00548b600c00b9a0159307cccf3347f1.jpg  \n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/train/images/save_dirrtake-12_jpg_cropped-jpg_jpg.rf.52431525a8df960d1e777c49ac53bd81.jpg  \n","   creating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/test/\n","   creating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/valid/\n","  inflating: Roboflow Export (841) no augments 21-03-14 18-19-19/Roboflow Export (841) no augments 21-03-14 18-19-19/data.yaml  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIcHCwWa9WWx","outputId":"27bd2b0f-46d9-44a2-9fb6-ca5c55fcae3d"},"source":["!ls \"{folder_name}/{folder_name}/train/images\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["digittake-23-jpg_jpg.rf.00548b600c00b9a0159307cccf3347f1.jpg\n","save_dirrsave_dirr36a73c74ef0b76639e12488651f587fb06a9baab-jpg-jpg_jpg.rf.cd4c51c05581425f5ff10b194f12f1e0.jpg\n","save_dirrtake-12_jpg_cropped-jpg_jpg.rf.52431525a8df960d1e777c49ac53bd81.jpg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DQlJKLji12yH"},"source":["#####architecture"]},{"cell_type":"code","metadata":{"id":"dby5JcxF1qIs"},"source":["# define number of classes based on YAML\n","import yaml\n","with open(\"data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttkXcDI71ipz","outputId":"2d9b93aa-f816-49d0-ac18-354693869870"},"source":["#this is the model configuration we will use for our tutorial \n","%cat /content/yolov5/models/yolov5s.yaml"],"execution_count":null,"outputs":[{"output_type":"stream","text":["# parameters\n","nc: 80  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, C3, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R183Gk8z1v5s"},"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XGVjUeKa1xhy"},"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJQdZ1nd1yys","outputId":"dc0f8be3-f7d5-4605-9896-1659ad8efde8"},"source":["# train yolov5s on custom data for 100 epochs\n","# time its performance\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 416 --batch 16 --epochs 10 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/yolov5\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 11 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (11/11), done.\n","From https://github.com/ultralytics/yolov5\n","   747c265..6f718ce  master     -> origin/master\n","\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 4 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n","YOLOv5 v4.0-130-g747c265 torch 1.8.0+cu101 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n","\n","Namespace(adam=False, batch_size=16, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='../data.yaml', device='', entity=None, epochs=10, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='yolov5s_results', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov5s_results2', single_cls=False, sync_bn=False, total_batch_size=16, weights='', workers=8, world_size=1)\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n","Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n","2021-03-14 04:34:06.981054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model Summary: 283 layers, 7279367 parameters, 7279367 gradients, 16.9 GFLOPS\n","\n","Scaled weight_decay = 0.0005\n","Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels' for images and labels... 769 found, 0 missing, 0 empty, 0 corrupted: 100% 769/769 [00:00<00:00, 2094.69it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB): 100% 769/769 [00:02<00:00, 382.82it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '../valid/labels' for images and labels... 307 found, 0 missing, 0 empty, 0 corrupted: 100% 307/307 [00:00<00:00, 868.71it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB): 100% 307/307 [00:00<00:00, 315.39it/s]\n","Plotting labels... \n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.73, Best Possible Recall (BPR) = 1.0000\n","Image sizes 416 train, 416 test\n","Using 2 dataloader workers\n","Logging results to runs/train/yolov5s_results2\n","Starting training for 10 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/9      1.8G    0.1056   0.07499   0.06345     0.244         4       416: 100% 49/49 [00:08<00:00,  5.78it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:02<00:00,  4.30it/s]\n","                 all         307        2687    7.55e-05      0.0108    1.32e-05    1.44e-06\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/9     1.84G    0.1007   0.07926   0.06249    0.2424         4       416: 100% 49/49 [00:07<00:00,  6.62it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:01<00:00,  6.28it/s]\n","                 all         307        2687    0.000139      0.0178    2.03e-05    2.17e-06\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/9     1.84G   0.09938   0.08061   0.06165    0.2416         3       416: 100% 49/49 [00:07<00:00,  6.82it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:01<00:00,  5.80it/s]\n","                 all         307        2687     0.00016      0.0203    3.37e-05    3.61e-06\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/9     1.84G   0.09813   0.07731   0.06153     0.237         3       416: 100% 49/49 [00:06<00:00,  7.12it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:02<00:00,  3.49it/s]\n","                 all         307        2687    0.000705       0.037      0.0001    1.24e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/9     1.84G   0.09725   0.08274    0.0611    0.2411         6       416: 100% 49/49 [00:06<00:00,  7.16it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:03<00:00,  3.09it/s]\n","                 all         307        2687     0.00111      0.0372    0.000274    3.72e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       5/9     1.84G   0.09619   0.08142   0.06066    0.2383        12       416: 100% 49/49 [00:06<00:00,  7.39it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:04<00:00,  2.18it/s]\n","                 all         307        2687     0.00365      0.0279    0.000976    0.000187\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       6/9     1.84G   0.09475   0.07687   0.06003    0.2316         1       416: 100% 49/49 [00:06<00:00,  7.09it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:08<00:00,  1.18it/s]\n","                 all         307        2687     0.00248      0.0708    0.000506    9.74e-05\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       7/9     1.84G   0.09298   0.07643   0.05998    0.2294         4       416: 100% 49/49 [00:06<00:00,  7.36it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:07<00:00,  1.29it/s]\n","                 all         307        2687      0.0184       0.133     0.00509    0.000893\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       8/9     1.84G   0.09185   0.06983   0.06026    0.2219         6       416: 100% 49/49 [00:06<00:00,  7.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:07<00:00,  1.28it/s]\n","                 all         307        2687      0.0316       0.169      0.0163     0.00309\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       9/9     1.84G    0.0895   0.06971   0.06006    0.2193        17       416: 100% 49/49 [00:06<00:00,  7.27it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 10/10 [00:10<00:00,  1.01s/it]\n","                 all         307        2687       0.042       0.188      0.0203     0.00435\n","                   1         307         351           0           0    0.000369    8.73e-05\n","                   2         307         417      0.0364       0.396      0.0265     0.00671\n","                   3         307         343      0.0509       0.198      0.0207     0.00506\n","                   4         307         268      0.0174       0.216     0.00834     0.00182\n","                   5         307         304      0.0457       0.273      0.0274     0.00568\n","                   6         307         175       0.126       0.137      0.0356     0.00733\n","                   7         307         148           0           0    0.000455    6.39e-05\n","                   8         307         169      0.0829       0.124      0.0316     0.00596\n","                   9         307         150      0.0325       0.367       0.035     0.00761\n","                   0         307         362       0.028       0.169      0.0167     0.00318\n","Optimizer stripped from runs/train/yolov5s_results2/weights/last.pt, 14.8MB\n","Optimizer stripped from runs/train/yolov5s_results2/weights/best.pt, 14.8MB\n","10 epochs completed in 0.037 hours.\n","\n","CPU times: user 676 ms, sys: 129 ms, total: 805 ms\n","Wall time: 2min 26s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BTU4x6MqINaO"},"source":[""],"execution_count":null,"outputs":[]}]}