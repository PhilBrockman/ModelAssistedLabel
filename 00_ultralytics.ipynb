{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/Coding/ModelAssistedLabel\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "%cd \"/content/drive/MyDrive/Coding/ModelAssistedLabel/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Default Values\n",
    "> These values will be accessable across this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Defaults:\n",
    "  \"\"\"\n",
    "  Helps keep a DRY principle across this project. The split ratio was defined based\n",
    "  on information found on Roboflow. `self.trainer_template` is pulled from the\n",
    "  YOLOv5 tutorial.\n",
    "\n",
    "  Any methods defined are there as a convenience for using ndbev in a Colab \n",
    "  enivornment.\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "    self.root = \"/content/drive/MyDrive/Coding/ModelAssistedLabel/\"\n",
    "    self.split_ratio = {\n",
    "              \"train\": .7,\n",
    "              \"valid\": .2,\n",
    "              \"test\": .1\n",
    "            }\n",
    "    self.data_yaml = \"\\n\".join([\"train: ../train/images\",\n",
    "    \"val: ../valid/images\",\n",
    "    \"\",\n",
    "    \"nc: 10\",\n",
    "    \"names: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\"])\n",
    "    self.resource_map = {\"images\": \".jpg\", \"labels\": \".txt\"}\n",
    "\n",
    "    self.trainer_template = f\"\"\"# parameters\n",
    "    nc: {10}  # number of classes\n",
    "    depth_multiple: 0.33  # model depth multiple\n",
    "    width_multiple: 0.50  # layer channel multiple\n",
    "\n",
    "    # anchors\n",
    "    anchors:\n",
    "      - [10,13, 16,30, 33,23]  # P3/8\n",
    "      - [30,61, 62,45, 59,119]  # P4/16\n",
    "      - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "    # YOLOv5 backbone\n",
    "    backbone:\n",
    "      # [from, number, module, args]\n",
    "      [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "      [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "      [-1, 3, BottleneckCSP, [128]],\n",
    "      [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "      [-1, 9, BottleneckCSP, [256]],\n",
    "      [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "      [-1, 9, BottleneckCSP, [512]],\n",
    "      [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "      [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "      [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
    "      ]\n",
    "\n",
    "    # YOLOv5 head\n",
    "    head:\n",
    "      [[-1, 1, Conv, [512, 1, 1]],\n",
    "      [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "      [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "      [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
    "\n",
    "      [-1, 1, Conv, [256, 1, 1]],\n",
    "      [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "      [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "      [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "      [-1, 1, Conv, [256, 3, 2]],\n",
    "      [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "      [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "      [-1, 1, Conv, [512, 3, 2]],\n",
    "      [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "      [-1, 3, BottleneckCSP, [1024, \n",
    "      False]],  # 23 (P5/32-large)\n",
    "\n",
    "      [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "      ]\"\"\"\n",
    "\n",
    "    calls = {}\n",
    "    calls[\"nbdev\"] = ([\"pip install nbdev\"])\n",
    "    calls[\"lib/docs\"] = ([\"nbdev_build_lib\", \"nbdev_build_docs\"])\n",
    "    self.calls = calls\n",
    "\n",
    "  def call_all(self, arr):\n",
    "    for x in arr:\n",
    "      os.system(x)\n",
    "\n",
    "  def nbdev(self):\n",
    "    for x in self.calls:\n",
    "      self.call_all(calls[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clone Ultralytics's YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.8.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "\n",
    "def prepare_YOLOv5():\n",
    "  \"\"\"\n",
    "  * Enter the project's root directory.\n",
    "  * Clone repository if the YOLOv5 directory does not exist.\n",
    "  * Install requirements.txt\n",
    "  * Check that GPU is enabled.\n",
    "  \"\"\"\n",
    "  os.chdir(\"{Defaults().root}\")\n",
    "  # safety for re-executions\n",
    "  if not os.path.exists(\"yolov5\"):\n",
    "    # clone YOLOv5 and reset to a specific git checkpoint that has been verified working\n",
    "    os.system(\"git clone https://github.com/ultralytics/yolov5\")  # clone repo\n",
    "    os.system(\"git reset --hard 68211f72c99915a15855f7b99bf5d93f5631330f\") # standardize models\n",
    "\n",
    "  # enter the yolov5 directory\n",
    "  os.chdir(\"yolov5\")\n",
    "\n",
    "  # install dependencies as necessary\n",
    "  os.system(\"pip install -qr requirements.txt\")  # install dependencies (ignore errors)\n",
    "  import torch\n",
    "\n",
    "  from IPython.display import Image, clear_output  # to display images\n",
    "  # from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "  clear_output()\n",
    "\n",
    "  if torch.cuda.is_available():\n",
    "    print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0)))\n",
    "  else:\n",
    "    raise Exception(\"You need to enable your GPU access to this runtime environment\")\n",
    "\n",
    "  # return to parent directory\n",
    "  os.chdir(\"..\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
