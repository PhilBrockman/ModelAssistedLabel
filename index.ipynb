{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Coding/ModelAssistedLabel\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# %load_ext autoreload \n",
    "# %autoreload 2\n",
    "%cd \"/content/drive/MyDrive/Coding/ModelAssistedLabel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Coding/ModelAssistedLabel\n",
      "install nbdev: \n",
      "git commit -m: updating background\n",
      "Converted 00_config.ipynb.\n",
      "Converted 01_split.ipynb.\n",
      "Converted 02_train.ipynb.\n",
      "Converted index.ipynb.\n",
      "converting: /content/drive/My Drive/Coding/ModelAssistedLabel/index.ipynb\n",
      "converting /content/drive/My Drive/Coding/ModelAssistedLabel/index.ipynb to README.md\n",
      "Executing: git config --local include.path ../.gitconfig\n",
      "Success: hooks are installed and repo's .gitconfig is now trusted\n",
      "\n",
      "[master 5fe1621] updating background\n",
      " 3 files changed, 5 insertions(+), 69 deletions(-)\n",
      "Counting objects: 6, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (6/6), done.\n",
      "Writing objects: 100% (6/6), 628 bytes | 157.00 KiB/s, done.\n",
      "Total 6 (delta 5), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n",
      "To https://github.com/PhilBrockman/ModelAssistedLabel.git\n",
      "   ead38e6..5fe1621  master -> master\n",
      "Branch 'master' set up to track remote branch 'master' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "# %run '_Synch.ipynb' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model-asisted Labeling with YOLOv5\n",
    "> bootstrapping image annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "Object Detection is great! ... if your labeled dataset already exists. I wanted to use machine learning to turn my regular rowing machine into a \"smart\" rowing machine (specifically: I want to track my workout stats).\n",
    "\n",
    "Unfortunately, I was unable to find a suitable existing set of labeled LCD digits.\n",
    "\n",
    "After working through [a Roboflow tutorial]( https://models.roboflow.com/object-detection/yolov5), I started to use Roboflow to annotate and store my images. \n",
    "\n",
    "I hated annotating my images by hand. Once my model began making reasonable guesses, I resolved to enlist the model's help in labeling new images. (I ended up building a [key-driven image labeler](https://github.com/PhilBrockman/autobbox) to modify my model's predictions, but that codebase is no longer being maintained.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Inputs:\n",
    "* **Labeled data** (for the model):\n",
    "  - All of the images and labels must be in a common folder (subfolders allowed).\n",
    "  - labels must be in [YOLOv5 format](https://github.com/AlexeyAB/Yolo_mark/issues/60).\n",
    "* **Unlabeled Data**:\n",
    "  - Hopefully similar enough to the labeled data that the model will be of assistance in labeling.\n",
    "\n",
    "\n",
    "> Note about file names: Pairs are based on sharing a base filename. For example `image.jpg/image.txt` would be paired as would `other_image5.jpg/other_image5.txt`.\n",
    "\n",
    "\n",
    "\n",
    "## Expected Output:\n",
    "\n",
    "* ***ZIP file*** that contains: \n",
    "    - `images/`\n",
    "      + a copy of every image in **Unlabeled Data**\n",
    "    - `labels/` (folder\n",
    "      + result of running object detection on each image\n",
    "    - a results folder produced by Ultralytic's `train.p` on the **Labeled Data**\n",
    "    - `classmap.yaml` to preserve the identity of the classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by cloning https://github.com/ultralytics/yolov5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# %run \"_Synch.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.8.0+cu101 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "from ModelAssistedLabel.core import Defaults\n",
    "import os\n",
    "\n",
    "# enter root directory\n",
    "os.chdir(Defaults().root)\n",
    "\n",
    "# clone yolov5 repo and install requirements\n",
    "# ensure GPU is enabled\n",
    "Defaults.prepare_YOLOv5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla image sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursively search a folder (`repo`) that contains images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary:  [{'train': 4}, {'valid': 1}, {'test': 0}]\n",
      "checksum: 5\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/digittake-52-jpg_jpg.rf.798cf1dcc7a60cbff6c43f5587082f4f.jpg | ./train/images/digittake-52-jpg_jpg.rf.798cf1dcc7a60cbff6c43f5587082f4f.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/digittake-52-jpg_jpg.rf.798cf1dcc7a60cbff6c43f5587082f4f.txt | ./train/labels/digittake-52-jpg_jpg.rf.798cf1dcc7a60cbff6c43f5587082f4f.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/save_dirrsave_dirrcd4d249fd27369f927124e67151b8d97e4bdfdd4-jpg-jpg_jpg.rf.5659d1ef98ace2d9f22fa90d114bf7d6.jpg | ./train/images/save_dirrsave_dirrcd4d249fd27369f927124e67151b8d97e4bdfdd4-jpg-jpg_jpg.rf.5659d1ef98ace2d9f22fa90d114bf7d6.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/save_dirrsave_dirrcd4d249fd27369f927124e67151b8d97e4bdfdd4-jpg-jpg_jpg.rf.5659d1ef98ace2d9f22fa90d114bf7d6.txt | ./train/labels/save_dirrsave_dirrcd4d249fd27369f927124e67151b8d97e4bdfdd4-jpg-jpg_jpg.rf.5659d1ef98ace2d9f22fa90d114bf7d6.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/digittake-106-jpg_jpg.rf.780b7e954c1a7786ba65757732ba9bf6.jpg | ./train/images/digittake-106-jpg_jpg.rf.780b7e954c1a7786ba65757732ba9bf6.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/digittake-106-jpg_jpg.rf.780b7e954c1a7786ba65757732ba9bf6.txt | ./train/labels/digittake-106-jpg_jpg.rf.780b7e954c1a7786ba65757732ba9bf6.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/screenytake-44-jpg-cropped-jpg_jpg.rf.43df93e453f9a236285b3cdd0469bc6f.jpg | ./train/images/screenytake-44-jpg-cropped-jpg_jpg.rf.43df93e453f9a236285b3cdd0469bc6f.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/screenytake-44-jpg-cropped-jpg_jpg.rf.43df93e453f9a236285b3cdd0469bc6f.txt | ./train/labels/screenytake-44-jpg-cropped-jpg_jpg.rf.43df93e453f9a236285b3cdd0469bc6f.txt\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/images/save_dirrtake-40-jpg-cropped-jpg-jpg_jpg.rf.296c8eb30772f8342ff64995ba9ad759.jpg | ./valid/images/save_dirrtake-40-jpg-cropped-jpg-jpg_jpg.rf.296c8eb30772f8342ff64995ba9ad759.jpg\n",
      "target/dest /content/drive/MyDrive/Coding/Roboflow Export (841)/labels/save_dirrtake-40-jpg-cropped-jpg-jpg_jpg.rf.296c8eb30772f8342ff64995ba9ad759.txt | ./valid/labels/save_dirrtake-40-jpg-cropped-jpg-jpg_jpg.rf.296c8eb30772f8342ff64995ba9ad759.txt\n"
     ]
    }
   ],
   "source": [
    "# repo = \"/content/drive/MyDrive/Coding/Roboflow Export (841)\"\n",
    "# name = \"nospaces\"\n",
    "# wm = AutoWeights(repo, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.02 ms, sys: 23.9 ms, total: 25.9 ms\n",
      "Wall time: 30.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./nospaces4-025678'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# wm.generate_weights(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
