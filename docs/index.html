---

title: Model-asisted Labeling with YOLOv5


keywords: fastai
sidebar: home_sidebar

summary: "custom image set annotation with a model's help"
description: "custom image set annotation with a model's help"
nb_path: "index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="https://github.com/PhilBrockman/ModelAssistedLabel/blob/master/modelassistedlabel%20splash.jpg?raw=true" alt="base64 splash"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Background">Background<a class="anchor-link" href="#Background"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>My exercise equipment doesn’t connect to a network. But I still want the "smart workout" experience when I'm using a "dumb" rowing machine.</p>
<p>Maybe if I point my webcam at the equipment’s LCD output, I can make a machine learn to identify and interpret useful information. Perfect! I’ll just utilize object detection to determine the location and identity of digits on the machine’s readout.</p>
<p>First question -- just a tiny one -- how do you do that?</p>
<p>After wading through several guides, I found <a href="https://models.roboflow.com/object-detection/yolov5">Roboflow's YOLOv5 tutorial</a>. They provide a hands-on and accessible experience in machine learning. But unfortunately, I couldn't progress immediately on my specific project. Instead, I had to build my own dataset.</p>
<p>As I labeled image after image, I fantasized passing my work off to a YOLOv5 model. As I sleuth through <a href="https://github.com/ultralytics/yolov5">Ultralytic's</a> original project, I build wrappers around <code>detect.py</code> and <code>train.py</code>. I determine that my fantasy could be a reality.</p>
<p>This repository contains the tools that let me "pre-label" my images before sending them off for human inspection and correction.
{% include note.html content='<code>./Image Repo/labeled/</code> contains a folder that holds all 841 labeled images.' %}</p>
<ul>
<li><code>Final Roboflow Export (841)</code> (841 labeled image dataset)
{% include note.html content='All images inside <code>./Image Repo/unlabeled</code> were taken inside a blacked-out room. Further, the lighting within each directory remains constant.' %}</li>
<li><code>21-3-22 rowing (200) 7:50-12:50</code> (200 images with direct lighting from one light source)</li>
<li><code>21-3-22 rowing (200) 1:53-7:00</code> (200 images with direct lighting from one light source and intermittent glare)</li>
<li><code>21-3-18 rowing 8-12</code> (200 images with direct light and ambient lamps turned on)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Getting-Started">Getting Started<a class="anchor-link" href="#Getting-Started"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>{% include tip.html content='<a href="https://colab.research.google.com/github/PhilBrockman/ModelAssistedLabel/blob/master/index.ipynb">Open In Colab</a>' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>git clone https://github.com/PhilBrockman/ModelAssistedLabel.git
<span class="o">%</span><span class="k">cd</span> &quot;ModelAssistedLabel&quot;
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Cloning into &#39;ModelAssistedLabel&#39;...
remote: Enumerating objects: 463, done.
remote: Counting objects: 100% (463/463), done.
remote: Compressing objects: 100% (146/146), done.
remote: Total 4440 (delta 332), reused 439 (delta 312), pack-reused 3977
Receiving objects: 100% (4440/4440), 210.50 MiB | 13.74 MiB/s, done.
Resolving deltas: 100% (1355/1355), done.
Checking out files: 100% (2381/2381), done.
/content/drive/MyDrive/vision.philbrockman.com/ModelAssistedLabel
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Expected-Inputs">Expected Inputs<a class="anchor-link" href="#Expected-Inputs"> </a></h3><ul>
<li><strong>labeled images</strong><ul>
<li>All of the images and labels must be in a common folder (subfolders allowed).</li>
<li>Labels must be in <a href="https://github.com/AlexeyAB/Yolo_mark/issues/60#issuecomment-401854885">YOLOv5 format</a>.
{% include note.html content='Image/label pairs are based on their base filename. For example <code>image.jpg/image.txt</code> would be paired as would <code>other_image5.jpg/other_image5.txt</code>.' %}</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">labeled_images</span>   <span class="o">=</span> <span class="s2">&quot;Image Repo/labeled/Final Roboflow Export (841)&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li><strong>unlabeled images</strong></li>
</ul>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">unlabeled_images</span> <span class="o">=</span> <span class="s2">&quot;Image Repo/unlabeled/21-3-22 rowing (200) 7:50-12:50&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Expected-Output">Expected Output<a class="anchor-link" href="#Expected-Output"> </a></h3><ul>
<li><strong>Folder</strong> that contains: <ul>
<li><code>images/</code><ul>
<li>a copy of every image in <strong>Unlabeled Data</strong></li>
</ul>
</li>
<li><code>labels/</code><ul>
<li>result of running object detection on each image</li>
</ul>
</li>
<li>a results folder produced by Ultralytic's <code>train.py</code> on the <strong>Labeled Data</strong> (if not using pre-trained weights)</li>
<li><code>class labels.txt</code> to preserve the identity of the classes</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Build the folder structure.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ModelAssistedLabel.config</span> <span class="kn">import</span> <span class="n">Defaults</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">project_name</span> <span class="o">=</span> <span class="s2">&quot;seven segment digits - &quot;</span>
<span class="n">export_folder</span> <span class="o">=</span> <span class="n">Defaults</span><span class="o">.</span><span class="n">_itername</span><span class="p">(</span><span class="n">project_name</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">export_folder</span><span class="p">)</span>
<span class="c1"># make the export folder</span>
<span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">export_folder</span><span class="p">)</span>

<span class="c1"># make the images and labels subfolders</span>
<span class="k">for</span> <span class="n">resource_folder</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">]:</span>
  <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_folder</span><span class="p">,</span> <span class="n">resource_folder</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>seven segment digits - 1
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The names of my classes are digits. Under the hood, the YOLOv5 model is working of the index of the class, rather than a human-readable name. Consequently, the identities of each class index must be supplied.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">class_idx</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="s1">&#39;5&#39;</span><span class="p">,</span> <span class="s1">&#39;6&#39;</span><span class="p">,</span> <span class="s1">&#39;7&#39;</span><span class="p">,</span> <span class="s1">&#39;8&#39;</span><span class="p">,</span> <span class="s1">&#39;9&#39;</span><span class="p">,</span> <span class="s1">&#39;0&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Store the class labels with index 0 on line 1, index 1 on line 2, and so on.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_folder</span><span class="p">,</span> <span class="s2">&quot;label_map.txt&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">label_map</span><span class="p">:</span>
  <span class="n">label_map</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">class_idx</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Configure-Defaults">Configure Defaults<a class="anchor-link" href="#Configure-Defaults"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Several values are stored by the <code>Defaults</code> class. Any value can be overridden (and new values can be added. Make sure to <code>save()</code> any changes! (changes are written to the <code>config_file</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span> <span class="o">=</span> <span class="n">Defaults</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; -- Defined Keys: --&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">keys</span><span class="p">()]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> -- Defined Keys: --
config_file
root
split_ratio
data_yaml
resource_map
trainer_template
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Speciy the absolute path of the root directory.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pwd
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>/content/drive/MyDrive/vision.philbrockman.com/ModelAssistedLabel
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="s2">&quot;/content/drive/MyDrive/vision.philbrockman.com/ModelAssistedLabel/&quot;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Save changes and enter root directory</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="n">d</span><span class="o">.</span><span class="n">to_root</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>moving to /content/drive/MyDrive/vision.philbrockman.com/ModelAssistedLabel/
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I borrow the instructions to set up the Ultralytics repo from <a href="https://models.roboflow.com/object-detection/yolov5">the Roboflow tutorial</a>. (If I'd be allowed one undo on this project, I wish I would have intially forked this project from that tutorial.)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>git clone https://github.com/ultralytics/yolov5  # clone repo

<span class="o">%</span><span class="k">cd</span> yolov5
<span class="c1"># install dependencies as necessary</span>
<span class="o">!</span>pip install -qr requirements.txt  # install dependencies <span class="o">(</span>ignore errors<span class="o">)</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">clear_output</span>  <span class="c1"># to display images</span>
<span class="kn">from</span> <span class="nn">utils.google_utils</span> <span class="kn">import</span> <span class="n">gdrive_download</span>  <span class="c1"># to download models/datasets</span>

<span class="o">%</span><span class="k">cd</span> ..
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Cloning into &#39;yolov5&#39;...
remote: Enumerating objects: 7, done.
remote: Counting objects: 100% (7/7), done.
remote: Compressing objects: 100% (7/7), done.
remote: Total 5532 (delta 1), reused 0 (delta 0), pack-reused 5525
Receiving objects: 100% (5532/5532), 8.15 MiB | 7.60 MiB/s, done.
Resolving deltas: 100% (3776/3776), done.
/content/drive/My Drive/vision.philbrockman.com/ModelAssistedLabel/yolov5
/content/drive/My Drive/vision.philbrockman.com/ModelAssistedLabel
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Make sure GPU is enabled.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Setup complete. Using torch </span><span class="si">%s</span><span class="s1"> </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="p">))</span>
  <span class="n">d</span><span class="o">.</span><span class="n">to_root</span><span class="p">()</span> <span class="c1">#step up a level</span>
<span class="k">else</span><span class="p">:</span>
   <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;enable GPU&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Setup complete. Using torch 1.8.0+cu101 _CudaDeviceProperties(name=&#39;Tesla P100-PCIE-16GB&#39;, major=6, minor=0, total_memory=16280MB, multi_processor_count=56)
moving to /content/drive/MyDrive/vision.philbrockman.com/ModelAssistedLabel/
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Generating-Weights">Generating Weights<a class="anchor-link" href="#Generating-Weights"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At some point, a model needs to be trained. I use <code>Generation</code> and <code>AutoWeights</code> to manage files relevant to the training process.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Preparing-Filesystem">Preparing Filesystem<a class="anchor-link" href="#Preparing-Filesystem"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>Generation</code> class helps convert an unordered folder of images and labels into a format compatible with YOLOv5. By default, the train/valid/test split is set to 70%/20%/10%.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ModelAssistedLabel.fileManagement</span> <span class="kn">import</span> <span class="n">Generation</span>

<span class="n">backup_dir</span> <span class="o">=</span> <span class="s2">&quot;archive/Generation/zips&quot;</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">Generation</span><span class="p">(</span><span class="n">repo</span><span class="o">=</span><span class="n">labeled_images</span><span class="p">,</span> 
               <span class="n">out_dir</span><span class="o">=</span><span class="n">backup_dir</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">g</span><span class="o">.</span><span class="n">set_split</span><span class="p">()</span>
<span class="n">g</span><span class="o">.</span><span class="n">get_split</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;train&#39;: 589}, {&#39;valid&#39;: 169}, {&#39;test&#39;: 83}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Backups are built into this system. As an intermediate step, the split must be written to disk in <code>g.out_dir</code>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">zipped</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">write_split_to_disk</span><span class="p">(</span><span class="n">descriptor</span><span class="o">=</span><span class="n">export_folder</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
dirs [&#39;./train&#39;, &#39;./valid&#39;, &#39;./test&#39;]
yaml archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03/data.yaml
subdir train
	outdir archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03
subdir valid
	outdir archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03
subdir test
	outdir archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03
os.listdir [&#39;train&#39;, &#39;valid&#39;, &#39;test&#39;, &#39;data.yaml&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, the images need to be written in a way so that the Ultralytics repository can understand their content. The <code>Autoweights</code> class both organizes data and create weights. Running an "initialize" command makes changes to the disk.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ModelAssistedLabel.train</span> <span class="kn">import</span> <span class="n">AutoWeights</span>
<span class="c1">#configure a basic AutoWeights class instance</span>
<span class="n">aw</span> <span class="o">=</span> <span class="n">AutoWeights</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">export_folder</span><span class="p">,</span> <span class="n">out_dir</span><span class="o">=</span><span class="n">backup_dir</span><span class="p">)</span>

<span class="c1"># create train/valid/test split from a bag of labeled images (recusively seek out images/labels)</span>
<span class="n">aw</span><span class="o">.</span><span class="n">initialize_images_from_zip</span><span class="p">(</span><span class="n">zipped</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>mv &#39;unzipped/archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03/train&#39; .
mv &#39;unzipped/archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03/valid&#39; .
mv &#39;unzipped/archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03/test&#39; .
mv &#39;unzipped/archive/Generation/zips/Final Roboflow Export (841)seven segment digits - 1 21-03-27 05-46-03/data.yaml&#39; .
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Peep on the sizes of the train/valid/test groups.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">aw</span><span class="o">.</span><span class="n">traverse_resources</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>train/images
	 &gt; 589 files
train/labels
	 &gt; 589 files
valid/images
	 &gt; 169 files
valid/labels
	 &gt; 169 files
test/images
	 &gt; 83 files
test/labels
	 &gt; 83 files
File:  data.yaml
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Running-train.py">Running <code>train.py</code><a class="anchor-link" href="#Running-train.py"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>With the images written to disk, we can run the Ultralytics training algorithm. I loved watching the progress fly by in real time on the original <code>train.py</code>. Fortunately, the Ultralytics folk write the results file to disk so the model's training data is still accessible!
{% include note.html content='this output has already been calculated and stored in <code>pre-trained/results</code> for convenience.' %}</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%</span><span class="k">time</span>

aw.generate_weights(epochs=2000, yaml_data=Defaults().trainer_template)
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 3s, sys: 10.8 s, total: 1min 14s
Wall time: 4h 57min 26s
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;yolov5/runs/train/seven segment digits - 1/&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The results folder is stored as an attribute as well, and it has a lot of data stored therein.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(&#39;yolov5/runs/train/seven segment digits - 1/&#39;, 22)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>However, the weights are stored in a subfolder called (aptly) "weights".</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span> <span class="o">+</span> <span class="s2">&quot;/weights&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;last.pt&#39;, &#39;best.pt&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Machine-assisted-Labeling">Machine-assisted Labeling<a class="anchor-link" href="#Machine-assisted-Labeling"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Labeling-a-New-Set-of-Images">Labeling a New Set of Images<a class="anchor-link" href="#Labeling-a-New-Set-of-Images"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>Viewer</code> class needs weights and class labels to operate.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">ModelAssistedLabel.detect</span> <span class="kn">import</span> <span class="n">Viewer</span>

<span class="c1"># access the folder of results from the AutoWeights instance</span>
<span class="n">results_folder</span> <span class="o">=</span> <span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span>

<span class="c1"># I&#39;m choosing to use the best weight.</span>
<span class="n">weight_path</span> <span class="o">=</span> <span class="n">results_folder</span> <span class="o">+</span> <span class="s2">&quot;/weights/best.pt&quot;</span>

<span class="c1"># Viewer needs a set of weights and an array of labels for the detected object types</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">Viewer</span><span class="p">(</span><span class="n">weight_path</span><span class="p">,</span> <span class="n">class_idx</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Fusing layers... 
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's us look through the computer's eyes at the images.</p>
<p>With the existing dataset, the model performs best under direct lighting.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline 
<span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">glob</span>

<span class="n">images</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./</span><span class="si">{</span><span class="n">unlabeled_images</span><span class="si">}</span><span class="s2">/*.jpg&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">images</span><span class="p">,</span><span class="mi">5</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="n">v</span><span class="o">.</span><span class="n">plot_for</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea ">
<pre>Output hidden; open in https://colab.research.google.com to view.</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this small sample, the model performs quite well. Nonetheless, manual review of all images is needed to remove overlapping predictions, categorization errors, and absent boxes.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
  <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">predict_for</span><span class="p">(</span><span class="n">image</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Exporting-Annotated-Images">Exporting Annotated Images<a class="anchor-link" href="#Exporting-Annotated-Images"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ensure that image/label pairs have a common root filename and collect relevant files in a single folder.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">random</span><span class="o">,</span> <span class="nn">PIL</span><span class="o">,</span> <span class="nn">shutil</span>
<span class="n">salt</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">())[</span><span class="mi">2</span><span class="p">:]</span>

<span class="k">for</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
  <span class="c1">#generate a likely-to-be-unique filename</span>
  <span class="n">shared_root</span> <span class="o">=</span> <span class="n">Defaults</span><span class="o">.</span><span class="n">_itername</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">project_name</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">salt</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

  <span class="c1">#save the image to the outfile</span>
  <span class="n">image</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="s2">&quot;image path&quot;</span><span class="p">])</span>
  <span class="n">image</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_folder</span><span class="p">,</span> <span class="s2">&quot;images&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">shared_root</span><span class="si">}</span><span class="s2">.jpg&quot;</span><span class="p">))</span>

  <span class="c1">#save the predictions to the outfile</span>
  <span class="n">predictions</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;predictions&quot;</span><span class="p">]</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">export_folder</span><span class="p">,</span> <span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">shared_root</span><span class="si">}</span><span class="s2">.txt&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">prediction_file</span><span class="p">:</span>
    <span class="n">prediction_file</span><span class="o">.</span><span class="n">writelines</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="s2">&quot;yolov5 format&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]))</span>

<span class="c1">#check if weights were generated</span>
<span class="k">if</span> <span class="n">aw</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Moving yolov5 results folder: </span><span class="si">{</span><span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">shutil</span><span class="o">.</span><span class="n">move</span><span class="p">(</span><span class="n">aw</span><span class="o">.</span><span class="n">last_results_path</span><span class="p">,</span> <span class="n">export_folder</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No weights to save&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Moving yolov5 results folder: yolov5/runs/train/seven segment digits - 1/
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I labeled dozens upon dozens and dozens of images with Roboflow and would recommend their free annotation service! However, to be transparent, I developed <a href="https://github.com/PhilBrockman/autobbox">an annotator</a> in React that better suited my physical needs.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wrap-Up">Wrap Up<a class="anchor-link" href="#Wrap-Up"> </a></h2><p>I have uncovered a camera and lighting positioning that allows for my model to read the LCD at with high fidelty. I'm using object detection as a form of OCR and it's working!</p>
<p>I see two main areas for development with this project. The first would be bolstering the dataset (and staying in the machine learning space). The second would be logic interpreting parsed data (building the "smart" software).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Lingering-Questions">Lingering Questions<a class="anchor-link" href="#Lingering-Questions"> </a></h3><p>My dataset of 841 images is eclectic. There's images from other rowing machines and others from <a href="https://github.com/SachaIZADI/Seven-Segment-OCR">a kind stranger's github repo</a>. Some images have been cropped to only include the display. Did having varied data slow me down overall? Or did it make the models more robust?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Recording-from-Laptop">Recording from Laptop<a class="anchor-link" href="#Recording-from-Laptop"> </a></h3><p>This is how I'm currently fixing the position my laptop while recording: <a href="https://raw.githubusercontent.com/PhilBrockman/ModelAssistedLabel/master/DIY-laptop-mount.jpg">standing</a>, <a href="https://raw.githubusercontent.com/PhilBrockman/ModelAssistedLabel/master/DIY-computer-capture.jpg">floor 1</a>, <a href="https://github.com/PhilBrockman/ModelAssistedLabel/blob/master/DIY-capture.jpeg?raw=true">floor 2</a>.</p>
<p>I use the <code>_capture.ipynb</code> notebook to capture images on a bit of a delay to prevent repeat images from cluttering the dataset. For me, it was much easier to get recording working from a local notebook than from a Colab notebook but YMMV.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="About-Me">About Me<a class="anchor-link" href="#About-Me"> </a></h3><p>I am finishing my fourth year as a public school teacher in Kentucky. This summer, I am moving to the Bay Area to pursue a career in tech. When I’m not coding, I enjoy playing violin! Reach me at phil.brockman@gmail.com.</p>

</div>
</div>
</div>
</div>
 

